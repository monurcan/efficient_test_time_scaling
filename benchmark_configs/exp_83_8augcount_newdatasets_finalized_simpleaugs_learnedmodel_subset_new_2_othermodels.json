{
    "model": {
        "TTAugAdapter_SmolVLM2_500M_16_SimplePara_learnedmodel": {
            "class": "TTAugAdapter_SmolVLM2",
            "model_args": {
                "model_path": "HuggingFaceTB/SmolVLM2-500M-Instruct"
            },
            "text_aug_args": {
                "gpt_paraphraser_strategy": "simple_paraphraser",
                "save_or_load": null,
                "path_text_aug_to_file": null
            },
            "image_aug_args": {
                "aug_strength": "high",
                "save_or_load_generativeimg": null,
                "strength_gen_aug": 0.25,
                "path_generativeimg_to_directory": null
            },
            "token_selection_aggregation_method": "learned_model",
            "number_of_versions": 16,
            "save_inputs_for_debugging": false,
            "pseudolabel_training_steps": 10,
            "pseudolabel_learning_rate": 4e-5,
            "pseudolabel_iterations": 1
        },
        "TTAugAdapter_SmolVLM2_256M_16_SimplePara_learnedmodel": {
            "class": "TTAugAdapter_SmolVLM2",
            "model_args": {
                "model_path": "HuggingFaceTB/SmolVLM2-256M-Video-Instruct"
            },
            "text_aug_args": {
                "gpt_paraphraser_strategy": "simple_paraphraser",
                "save_or_load": null,
                "path_text_aug_to_file": null
            },
            "image_aug_args": {
                "aug_strength": "high",
                "save_or_load_generativeimg": null,
                "strength_gen_aug": 0.25,
                "path_generativeimg_to_directory": null
            },
            "token_selection_aggregation_method": "learned_model",
            "number_of_versions": 16,
            "save_inputs_for_debugging": false,
            "pseudolabel_training_steps": 10,
            "pseudolabel_learning_rate": 4e-5,
            "pseudolabel_iterations": 1
        },
        "TTAugAdapter_SmolVLM2_500M_16_SimplePara_average": {
            "class": "TTAugAdapter_SmolVLM2",
            "model_args": {
                "model_path": "HuggingFaceTB/SmolVLM2-500M-Instruct"
            },
            "text_aug_args": {
                "gpt_paraphraser_strategy": "simple_paraphraser",
                "save_or_load": null,
                "path_text_aug_to_file": null
            },
            "image_aug_args": {
                "aug_strength": "high",
                "save_or_load_generativeimg": null,
                "strength_gen_aug": 0.25,
                "path_generativeimg_to_directory": null
            },
            "token_selection_aggregation_method": "average",
            "number_of_versions": 16,
            "save_inputs_for_debugging": false
        },
        "TTAugAdapter_SmolVLM2_256M_16_SimplePara_average": {
            "class": "TTAugAdapter_SmolVLM2",
            "model_args": {
                "model_path": "HuggingFaceTB/SmolVLM2-256M-Video-Instruct"
            },
            "text_aug_args": {
                "gpt_paraphraser_strategy": "simple_paraphraser",
                "save_or_load": null,
                "path_text_aug_to_file": null
            },
            "image_aug_args": {
                "aug_strength": "high",
                "save_or_load_generativeimg": null,
                "strength_gen_aug": 0.25,
                "path_generativeimg_to_directory": null
            },
            "token_selection_aggregation_method": "average",
            "number_of_versions": 16,
            "save_inputs_for_debugging": false
        }
    },
    "data": {
        "OCRBench": {
            "class": "OCRBench",
            "dataset": "OCRBench"
        },
        "MME-RealWorld-Lite": {
            "class": "MMERealWorld",
            "dataset": "MME-RealWorld-Lite"
        },
        "AMBER": {
            "class": "ImageYORNDataset",
            "dataset": "AMBER"
        },
        "TextVQA_VAL": {
            "class": "ImageVQADataset",
            "dataset": "TextVQA_VAL"
        },
        "AI2D_TEST": {
            "class": "ImageMCQDataset",
            "dataset": "AI2D_TEST"
        },
        "OCRVQA_TEST": {
            "class": "ImageVQADataset",
            "dataset": "OCRVQA_TEST"
        },
        "ChartQA_TEST": {
            "class": "ImageVQADataset",
            "dataset": "ChartQA_TEST"
        },
        "GQA_TestDev_Balanced": {
            "class": "ImageVQADataset",
            "dataset": "GQA_TestDev_Balanced"
        },
        "COCO_VAL": {
            "class": "ImageCaptionDataset",
            "dataset": "COCO_VAL"
        }
    }
}