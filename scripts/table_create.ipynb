{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def parse_scores_string(s):\n",
    "    \"\"\"\n",
    "    Converts a string representation of a list (e.g., \"[71.42857, 71.42857]\") into a list of floats.\n",
    "    \"\"\"\n",
    "    s = s.strip(\"[]\")\n",
    "    if not s:\n",
    "        return []\n",
    "    return [float(x.strip()) for x in s.split(\",\")]\n",
    "\n",
    "def extract_overall_scores(directory, n_samples=20, skip_if=None):\n",
    "    \"\"\"\n",
    "    Reads all .csv and .json files in the given directory and extracts the \"Overall\" score\n",
    "    from .csv files, \"CIDEr\" score from .json files, \"Jaccard\" score from .json files with specific keys,\n",
    "    and \"Final Score Norm\" from certain JSON files.\n",
    "    Handles cases where \"Overall\" is a column or a row in .csv files, and supports additional formats with \"Overall Score\".\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing .csv and .json files.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are filenames and values are the extracted scores.\n",
    "    \"\"\"\n",
    "    overall_scores = {}\n",
    "    if skip_if is None:\n",
    "        skip_if = []\n",
    "        \n",
    "    skip_if.extend([\"MMVet_gpt-4-turbo_score_fine.csv\", \"MMDU_gpt-4o_score.csv\"], )\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        skip_this_file = False\n",
    "        for skip in skip_if:\n",
    "            if skip in filename:\n",
    "                skip_this_file = True\n",
    "                break\n",
    "        if skip_this_file:\n",
    "            continue\n",
    "        \n",
    "        filename = filename.replace(Path(directory).name + \"_\", \"\")\n",
    "        \n",
    "        if filename.endswith('.csv'):\n",
    "            try:\n",
    "                # Load the CSV file into a pandas DataFrame\n",
    "                df = pd.read_csv(filepath)\n",
    "\n",
    "                if \"split\" in df.columns and \"average_scores\" in df.columns:\n",
    "                    fintab_value = None\n",
    "                    vwtq_value = None\n",
    "\n",
    "                    # Process fintabnetqa row: extract first element from list string\n",
    "                    if \"fintabnetqa\" in df[\"split\"].values:\n",
    "                        fintab_row = df[df[\"split\"] == \"fintabnetqa\"].iloc[0]\n",
    "                        fintab_list = parse_scores_string(fintab_row[\"average_scores\"])\n",
    "                        fintab_value = fintab_list[0] if fintab_list else None\n",
    "\n",
    "                    # Process vwtq row: extract first element from list string\n",
    "                    if \"vwtq\" in df[\"split\"].values:\n",
    "                        vwtq_row = df[df[\"split\"] == \"vwtq\"].iloc[0]\n",
    "                        vwtq_list = parse_scores_string(vwtq_row[\"average_scores\"])\n",
    "                        vwtq_value = vwtq_list[0] if vwtq_list else None\n",
    "\n",
    "                    # Directly assign overall_score as the average of the two values\n",
    "                    overall_score = (fintab_value / 100 + vwtq_value / 100) / 2 if (fintab_value is not None and vwtq_value is not None) else None\n",
    "                elif \"Overall\" in df.columns:\n",
    "                    if \"MathVerse\" in filename or \"TextVQA\" in filename:\n",
    "                        overall_score = df[\"Overall\"].iloc[-1] / 100\n",
    "                    else:\n",
    "                        # Extract the \"Overall\" score from the first row\n",
    "                        overall_score = df[\"Overall\"].iloc[0]\n",
    "                elif \"Overall Score\" in df.columns:\n",
    "                    # MMDU\n",
    "                    # Extract the \"Overall Score\" from the row where \"set\" is \"all\"\n",
    "                    overall_row = df[df[\"set\"] == \"all\"]\n",
    "                    overall_score = overall_row[\"Overall Score\"].iloc[0] if not overall_row.empty else None\n",
    "                elif \"Avg ACC\" in df.columns:\n",
    "                    # New case: Extract the \"Avg ACC\" score from the first row\n",
    "                    overall_score = df[\"Avg ACC\"].iloc[0] / 100\n",
    "                elif \"split\" in df.columns and \"aAcc\" in df.columns:\n",
    "                    overall_row = df[df[\"split\"] == \"Overall\"]\n",
    "                    overall_score = overall_row[\"aAcc\"].iloc[0] / 100 if not overall_row.empty else None\n",
    "                else:\n",
    "                    # MMVET\n",
    "                    # Check if \"Overall\" is in the first column (as a row)\n",
    "                    overall_row = df[df.iloc[:, 0] == \"Overall\"]\n",
    "                    if not overall_row.empty:\n",
    "                        overall_score = overall_row.iloc[0, df.columns.get_loc(\"acc\")] / 100 # Extract score from \"acc\" column\n",
    "                    else:\n",
    "                        overall_score = None  # \"Overall\" not found\n",
    "\n",
    "\n",
    "                if overall_score is not None and any(f in filename for f in [\"POPE_score.csv\", \"OCRVQA_TEST_acc.csv\", \"ChartQA_TEST_acc.csv\", \"GQA_TestDev_Balanced_acc.csv\", \"MathVerse_MINI\"]):\n",
    "                    # If it's likely a percentage (e.g., > 1), divide by 100\n",
    "                    # if overall_score > 1:\n",
    "                    overall_score /= 100\n",
    "\n",
    "                # overall_scores[filename + \" (Accuracy)\"] = overall_score\n",
    "                overall_scores[filename.replace(\".csv\", \"\")] = overall_score\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "                overall_scores[filename] = None\n",
    "\n",
    "        elif filename.endswith('.json'):\n",
    "            try:\n",
    "                # Load the JSON file\n",
    "                with open(filepath, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                # Extract the \"CIDEr\" score if available\n",
    "                if \"ROUGE_L\" in data:\n",
    "                    overall_scores[filename + \" (ROUGE_L)\"] = data.get(\"ROUGE_L\", None) / 100\n",
    "                # Extract the \"Jaccard\" score if available\n",
    "                elif \"Jaccard\" in data:\n",
    "                    overall_scores[filename + \" (Jaccard)\"] = data.get(\"Jaccard\", None) / 1\n",
    "                # Extract the \"Final Score Norm\" if available\n",
    "                elif \"Final Score\" in data:\n",
    "                    overall_scores[filename + \" (Accuracy)\"] = data.get(\"Final Score\", None) / n_samples\n",
    "                elif \"Overall\" in data:\n",
    "                    overall_scores[filename + \" (Accuracy)\"] = data[\"Overall\"]\n",
    "                elif \"Average\" in data:\n",
    "                    overall_scores[filename + \" (Accuracy)\"] = data[\"Average\"] / 100\n",
    "                else:\n",
    "                    overall_scores[filename] = None\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "                overall_scores[filename] = None\n",
    "\n",
    "    overall_scores = dict(sorted(overall_scores.items(), key=lambda item: item[0]))\n",
    "    return overall_scores\n",
    "\n",
    "def create_table(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df[df[\"Metric\"] != \"MMVet_gpt-4-turbo_score_fine.csv\"]\n",
    "\n",
    "    keys = list(data.keys())\n",
    "    keys.remove(\"Metric\")\n",
    "\n",
    "    # Calculate normalized sum\n",
    "    normalized_sums = {\n",
    "        # key: (df[key] / df[keys].mean(axis=1)).sum()\n",
    "        key: (df[key]).mean()\n",
    "        for key in keys\n",
    "    }\n",
    "\n",
    "    # Create a new row for normalized sum\n",
    "    normalized_sum_row = pd.DataFrame([{\"Metric\": \"Mean\", **normalized_sums}])\n",
    "\n",
    "    # Concatenate the normalized sum row with the original DataFrame\n",
    "    final_df = pd.concat([df, normalized_sum_row], ignore_index=True)\n",
    "\n",
    "    # Format numeric columns to two decimal places\n",
    "    numeric_columns = keys\n",
    "    for col in numeric_columns:\n",
    "        final_df[col] = (pd.to_numeric(final_df[col], errors=\"coerce\") * 100).round(1)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "def create_table_from_dict(name_path_dict, skip_if=None, n_samples=20):\n",
    "    if skip_if is None:\n",
    "        skip_if = []\n",
    "        \n",
    "    # print(min([[key.split(\"_\", 1)[-1] for key in extract_overall_scores(path).keys()] for path in list(name_path_dict.values())], key=len))\n",
    "    # print(extract_overall_scores(next(iter(name_path_dict.values())), skip_if=skip_if, n_samples=n_samples).keys())\n",
    "    # print([Path(key).name for key in name_path_dict.values()])\n",
    "    \n",
    "    return create_table({\n",
    "        \"Metric\": [key.split(\"_\", 1)[-1] for key in extract_overall_scores(next(iter(name_path_dict.values())), skip_if=skip_if, n_samples=n_samples).keys()],\n",
    "        **{\n",
    "            key: extract_overall_scores(value, skip_if=skip_if, n_samples=n_samples).values()\n",
    "            for key, value in name_path_dict.items()\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_table_from_dict_fillna(name_path_dict, skip_if=None, n_samples=20):\n",
    "    if skip_if is None:\n",
    "        skip_if = []\n",
    "        \n",
    "    reference_max_benchmarks = list({\n",
    "        key\n",
    "        for path in list(name_path_dict.values())\n",
    "        for key in extract_overall_scores(path, skip_if=skip_if, n_samples=n_samples).keys()\n",
    "    })\n",
    "    \n",
    "    result = {\n",
    "        \"Metric\": reference_max_benchmarks\n",
    "    }\n",
    "    for key, value in name_path_dict.items():\n",
    "        key_val_all_benchmarks = extract_overall_scores(value, skip_if=skip_if, n_samples=n_samples)\n",
    "        key_val_max_benchmarks = {}\n",
    "        # for key_one_bench, val_one_bench in key_val_all_benchmarks.items():\n",
    "        #     if key_one_bench not in reference_max_benchmarks:\n",
    "        #         key_val_max_benchmarks[key_one_bench] = np.nan\n",
    "        #     else:\n",
    "        #         key_val_max_benchmarks[key_one_bench] = val_one_bench            \n",
    "        for ref_key in reference_max_benchmarks:\n",
    "            if ref_key in key_val_all_benchmarks:\n",
    "                key_val_max_benchmarks[ref_key] = key_val_all_benchmarks[ref_key]\n",
    "            else:\n",
    "                key_val_max_benchmarks[ref_key] = np.nan  # np.nan or None or 0 or whatever you want to fill missing values with. Here we use np.nan.\n",
    "        \n",
    "        result[key] = key_val_max_benchmarks.values()\n",
    "    \n",
    "    # print(result)\n",
    "    # for key, value in result.items():\n",
    "    #     print(key, len(value))\n",
    "    \n",
    "    return create_table(result)\n",
    "\n",
    "\n",
    "def create_table_from_dict_skipna(name_path_dict, skip_if=None, n_samples=20):\n",
    "    if skip_if is None:\n",
    "        skip_if = []\n",
    "        \n",
    "    reference_max_benchmarks = list(set.intersection(*[\n",
    "        set(extract_overall_scores(path, skip_if=skip_if, n_samples=n_samples).keys()) for path in name_path_dict.values()\n",
    "    ]))\n",
    "\n",
    "    result = {\n",
    "        \"Metric\": reference_max_benchmarks\n",
    "    }\n",
    "    for key, value in name_path_dict.items():\n",
    "        key_val_all_benchmarks = extract_overall_scores(value, skip_if=skip_if, n_samples=n_samples)\n",
    "        key_val_max_benchmarks = {}\n",
    "        \n",
    "        for ref_key in reference_max_benchmarks:\n",
    "            if ref_key in key_val_all_benchmarks:\n",
    "                key_val_max_benchmarks[ref_key] = key_val_all_benchmarks[ref_key]\n",
    "            else:\n",
    "                key_val_max_benchmarks[ref_key] = np.nan  # np.nan or None or 0 or whatever you want to fill missing values with. Here we use np.nan.\n",
    "        \n",
    "        result[key] = key_val_max_benchmarks.values()\n",
    "    \n",
    "    # print(result)\n",
    "    # for key, value in result.items():\n",
    "    #     print(key, len(value))\n",
    "    \n",
    "    return create_table(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>base</th>\n",
       "      <th>answr_lvl_temp_majority_vote</th>\n",
       "      <th>answr_lvl_temp_mllm_selector</th>\n",
       "      <th>answr_lvl_temp_confidence_selector</th>\n",
       "      <th>answr_lvl_temp_mllm_synthesizer</th>\n",
       "      <th>tta8_av</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI2D_TEST_acc</td>\n",
       "      <td>68.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>69.2</td>\n",
       "      <td>69.1</td>\n",
       "      <td>67.4</td>\n",
       "      <td>68.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TextVQA_VAL_acc</td>\n",
       "      <td>73.2</td>\n",
       "      <td>72.6</td>\n",
       "      <td>71.6</td>\n",
       "      <td>69.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChartQA_TEST_acc</td>\n",
       "      <td>74.2</td>\n",
       "      <td>74.4</td>\n",
       "      <td>73.4</td>\n",
       "      <td>72.5</td>\n",
       "      <td>71.7</td>\n",
       "      <td>75.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMBER_score</td>\n",
       "      <td>68.7</td>\n",
       "      <td>70.4</td>\n",
       "      <td>64.5</td>\n",
       "      <td>53.5</td>\n",
       "      <td>67.8</td>\n",
       "      <td>75.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GQA_TestDev_Balanced_acc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OCRVQA_TEST_acc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OCRBench_score.json (Accuracy)</td>\n",
       "      <td>72.9</td>\n",
       "      <td>72.6</td>\n",
       "      <td>71.9</td>\n",
       "      <td>70.2</td>\n",
       "      <td>71.9</td>\n",
       "      <td>73.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MME-RealWorld-Lite_rating.json (Accuracy)</td>\n",
       "      <td>27.8</td>\n",
       "      <td>26.2</td>\n",
       "      <td>26.4</td>\n",
       "      <td>27.6</td>\n",
       "      <td>27.6</td>\n",
       "      <td>31.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COCO_VAL_score.json (ROUGE_L)</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>16.7</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mean</td>\n",
       "      <td>43.8</td>\n",
       "      <td>36.4</td>\n",
       "      <td>42.8</td>\n",
       "      <td>41.0</td>\n",
       "      <td>43.9</td>\n",
       "      <td>47.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Metric  base  \\\n",
       "0                              AI2D_TEST_acc  68.5   \n",
       "1                            TextVQA_VAL_acc  73.2   \n",
       "2                           ChartQA_TEST_acc  74.2   \n",
       "3                                AMBER_score  68.7   \n",
       "4                   GQA_TestDev_Balanced_acc   0.0   \n",
       "5                            OCRVQA_TEST_acc   0.0   \n",
       "6             OCRBench_score.json (Accuracy)  72.9   \n",
       "7  MME-RealWorld-Lite_rating.json (Accuracy)  27.8   \n",
       "8              COCO_VAL_score.json (ROUGE_L)   9.1   \n",
       "9                                       Mean  43.8   \n",
       "\n",
       "   answr_lvl_temp_majority_vote  answr_lvl_temp_mllm_selector  \\\n",
       "0                           3.1                          69.2   \n",
       "1                          72.6                          71.6   \n",
       "2                          74.4                          73.4   \n",
       "3                          70.4                          64.5   \n",
       "4                           0.0                           0.0   \n",
       "5                           0.0                           0.0   \n",
       "6                          72.6                          71.9   \n",
       "7                          26.2                          26.4   \n",
       "8                           8.2                           8.4   \n",
       "9                          36.4                          42.8   \n",
       "\n",
       "   answr_lvl_temp_confidence_selector  answr_lvl_temp_mllm_synthesizer  \\\n",
       "0                                69.1                             67.4   \n",
       "1                                69.5                             72.0   \n",
       "2                                72.5                             71.7   \n",
       "3                                53.5                             67.8   \n",
       "4                                 0.0                              0.0   \n",
       "5                                 0.0                              0.2   \n",
       "6                                70.2                             71.9   \n",
       "7                                27.6                             27.6   \n",
       "8                                 6.2                             16.7   \n",
       "9                                41.0                             43.9   \n",
       "\n",
       "   tta8_av  \n",
       "0     68.8  \n",
       "1     72.8  \n",
       "2     75.6  \n",
       "3     75.4  \n",
       "4      5.8  \n",
       "5     11.8  \n",
       "6     73.4  \n",
       "7     31.1  \n",
       "8     15.9  \n",
       "9     47.9  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparison with other test-time scaling methods\n",
    "create_table_from_dict_fillna({\n",
    "    \"base\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized/Base_SmolVLM2_2B\",\n",
    "    \n",
    "    \"answr_lvl_temp_majority_vote\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_answerlevels_selfconsistency/TTAugAdapter_SmolVLM2_2B_8_AnswerLevelTemperatureMajorityVote\",\n",
    "    # \"answr_lvl_greedy_majority_vote\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_answerlevels_selfconsistency/TTAugAdapter_SmolVLM2_2B_8_AnswerLevelGreedyMajorityVote\",\n",
    "    \n",
    "    \"answr_lvl_temp_mllm_selector\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_answerlevels/TTAugAdapter_SmolVLM2_2B_8_AnswerLevelTemperatureMLLMSelector\",\n",
    "    # \"answr_lvl_greedy_mllm_selector\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_answerlevels/TTAugAdapter_SmolVLM2_2B_8_AnswerLevelGreedyMLLMSelector\",\n",
    "    \n",
    "    \"answr_lvl_temp_confidence_selector\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_answerlevels_temp_confidence/TTAugAdapter_SmolVLM2_2B_8_AnswerLevelTemperatureConfidenceSelector\",\n",
    "    # \"answr_lvl_greedy_confidence_selector\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_answerlevels_confidence/TTAugAdapter_SmolVLM2_2B_8_AnswerLevelTemperatureMLLMSelector\",\n",
    "    \n",
    "    \"answr_lvl_temp_mllm_synthesizer\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_answerlevels_temp_mllmsynthesizer/TTAugAdapter_SmolVLM2_2B_8_AnswerLevelTemperatureMLLMSynthesizer\",\n",
    "    # \"answr_lvl_greedy_mllm_synthesizer\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_answerlevels_mllmsynthesizer/TTAugAdapter_SmolVLM2_2B_8_AnswerLevelTemperatureMLLMSynthesizer\",\n",
    "    \n",
    "    \"tta8_av\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized/TTAugAdapter_SmolVLM2_2B_8_SimplePara_average\",\n",
    "}, n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>base</th>\n",
       "      <th>tta8_mostconf</th>\n",
       "      <th>tta8_majority</th>\n",
       "      <th>tta8_ewm</th>\n",
       "      <th>tta8_av</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MME-RealWorld-Lite_rating.json (Accuracy)</td>\n",
       "      <td>27.8</td>\n",
       "      <td>29.5</td>\n",
       "      <td>30.4</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCRBench_score.json (Accuracy)</td>\n",
       "      <td>72.9</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.2</td>\n",
       "      <td>73.4</td>\n",
       "      <td>73.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChartQA_TEST_acc</td>\n",
       "      <td>74.2</td>\n",
       "      <td>73.6</td>\n",
       "      <td>74.8</td>\n",
       "      <td>76.6</td>\n",
       "      <td>75.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GQA_TestDev_Balanced_acc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OCRVQA_TEST_acc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI2D_TEST_acc</td>\n",
       "      <td>68.5</td>\n",
       "      <td>68.7</td>\n",
       "      <td>68.7</td>\n",
       "      <td>68.8</td>\n",
       "      <td>68.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TextVQA_VAL_acc</td>\n",
       "      <td>73.2</td>\n",
       "      <td>70.5</td>\n",
       "      <td>71.5</td>\n",
       "      <td>73.3</td>\n",
       "      <td>72.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMBER_score</td>\n",
       "      <td>68.7</td>\n",
       "      <td>72.3</td>\n",
       "      <td>71.4</td>\n",
       "      <td>74.6</td>\n",
       "      <td>75.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COCO_VAL_score.json (ROUGE_L)</td>\n",
       "      <td>9.1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>18.4</td>\n",
       "      <td>14.6</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mean</td>\n",
       "      <td>43.8</td>\n",
       "      <td>45.6</td>\n",
       "      <td>46.6</td>\n",
       "      <td>47.6</td>\n",
       "      <td>47.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Metric  base  tta8_mostconf  \\\n",
       "0  MME-RealWorld-Lite_rating.json (Accuracy)  27.8           29.5   \n",
       "1             OCRBench_score.json (Accuracy)  72.9           72.0   \n",
       "2                           ChartQA_TEST_acc  74.2           73.6   \n",
       "3                   GQA_TestDev_Balanced_acc   0.0            6.1   \n",
       "4                            OCRVQA_TEST_acc   0.0            3.5   \n",
       "5                              AI2D_TEST_acc  68.5           68.7   \n",
       "6                            TextVQA_VAL_acc  73.2           70.5   \n",
       "7                                AMBER_score  68.7           72.3   \n",
       "8              COCO_VAL_score.json (ROUGE_L)   9.1           14.2   \n",
       "9                                       Mean  43.8           45.6   \n",
       "\n",
       "   tta8_majority  tta8_ewm  tta8_av  \n",
       "0           30.4      31.0     31.1  \n",
       "1           72.2      73.4     73.4  \n",
       "2           74.8      76.6     75.6  \n",
       "3            3.4       4.3      5.8  \n",
       "4            9.0      11.4     11.8  \n",
       "5           68.7      68.8     68.8  \n",
       "6           71.5      73.3     72.8  \n",
       "7           71.4      74.6     75.4  \n",
       "8           18.4      14.6     15.9  \n",
       "9           46.6      47.6     47.9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different aggregation methods\n",
    "create_table_from_dict_fillna({\n",
    "    \"base\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized/Base_SmolVLM2_2B\",\n",
    "    \"tta8_mostconf\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized/TTAugAdapter_SmolVLM2_2B_8_SimplePara_mostconf\",\n",
    "    \"tta8_majority\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_continue/TTAugAdapter_SmolVLM2_2B_8_SimplePara_majority\",\n",
    "    \"tta8_ewm\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_continue/TTAugAdapter_SmolVLM2_2B_8_SimplePara_ewm\",\n",
    "    \"tta8_av\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized/TTAugAdapter_SmolVLM2_2B_8_SimplePara_average\",\n",
    "}, n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>base</th>\n",
       "      <th>tta2_av</th>\n",
       "      <th>tta4_av</th>\n",
       "      <th>tta8_av</th>\n",
       "      <th>tta16_av</th>\n",
       "      <th>tta32_av</th>\n",
       "      <th>tta64_av</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MME-RealWorld-Lite_rating.json (Accuracy)</td>\n",
       "      <td>27.8</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>31.1</td>\n",
       "      <td>31.9</td>\n",
       "      <td>31.8</td>\n",
       "      <td>32.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCRBench_score.json (Accuracy)</td>\n",
       "      <td>72.9</td>\n",
       "      <td>72.1</td>\n",
       "      <td>73.9</td>\n",
       "      <td>73.4</td>\n",
       "      <td>73.7</td>\n",
       "      <td>72.2</td>\n",
       "      <td>72.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChartQA_TEST_acc</td>\n",
       "      <td>74.2</td>\n",
       "      <td>75.1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.6</td>\n",
       "      <td>76.1</td>\n",
       "      <td>76.7</td>\n",
       "      <td>76.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GQA_TestDev_Balanced_acc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OCRVQA_TEST_acc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.8</td>\n",
       "      <td>12.6</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI2D_TEST_acc</td>\n",
       "      <td>68.5</td>\n",
       "      <td>69.2</td>\n",
       "      <td>68.9</td>\n",
       "      <td>68.8</td>\n",
       "      <td>69.6</td>\n",
       "      <td>68.5</td>\n",
       "      <td>69.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TextVQA_VAL_acc</td>\n",
       "      <td>73.2</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>72.8</td>\n",
       "      <td>72.4</td>\n",
       "      <td>72.4</td>\n",
       "      <td>72.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMBER_score</td>\n",
       "      <td>68.7</td>\n",
       "      <td>72.4</td>\n",
       "      <td>74.3</td>\n",
       "      <td>75.4</td>\n",
       "      <td>75.9</td>\n",
       "      <td>76.9</td>\n",
       "      <td>77.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COCO_VAL_score.json (ROUGE_L)</td>\n",
       "      <td>9.1</td>\n",
       "      <td>12.1</td>\n",
       "      <td>14.4</td>\n",
       "      <td>15.9</td>\n",
       "      <td>16.9</td>\n",
       "      <td>17.2</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mean</td>\n",
       "      <td>43.8</td>\n",
       "      <td>45.1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.9</td>\n",
       "      <td>48.3</td>\n",
       "      <td>48.3</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Metric  base  tta2_av  tta4_av  tta8_av  \\\n",
       "0  MME-RealWorld-Lite_rating.json (Accuracy)  27.8     31.0     30.8     31.1   \n",
       "1             OCRBench_score.json (Accuracy)  72.9     72.1     73.9     73.4   \n",
       "2                           ChartQA_TEST_acc  74.2     75.1     75.0     75.6   \n",
       "3                   GQA_TestDev_Balanced_acc   0.0      1.1      3.7      5.8   \n",
       "4                            OCRVQA_TEST_acc   0.0      1.2      9.4     11.8   \n",
       "5                              AI2D_TEST_acc  68.5     69.2     68.9     68.8   \n",
       "6                            TextVQA_VAL_acc  73.2     72.0     73.0     72.8   \n",
       "7                                AMBER_score  68.7     72.4     74.3     75.4   \n",
       "8              COCO_VAL_score.json (ROUGE_L)   9.1     12.1     14.4     15.9   \n",
       "9                                       Mean  43.8     45.1     47.0     47.9   \n",
       "\n",
       "   tta16_av  tta32_av  tta64_av  \n",
       "0      31.9      31.8      32.1  \n",
       "1      73.7      72.2      72.8  \n",
       "2      76.1      76.7      76.3  \n",
       "3       5.5       6.4       5.2  \n",
       "4      12.6      12.7      13.5  \n",
       "5      69.6      68.5      69.3  \n",
       "6      72.4      72.4      72.2  \n",
       "7      75.9      76.9      77.4  \n",
       "8      16.9      17.2      16.9  \n",
       "9      48.3      48.3      48.4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling: Number of Augmentations\n",
    "create_table_from_dict_fillna({\n",
    "    \"base\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized/Base_SmolVLM2_2B\",\n",
    "    \"tta2_av\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_continuee/TTAugAdapter_SmolVLM2_2B_2_SimplePara_average\",\n",
    "    \"tta4_av\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_continuee/TTAugAdapter_SmolVLM2_2B_4_SimplePara_average\",\n",
    "    \"tta8_av\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized/TTAugAdapter_SmolVLM2_2B_8_SimplePara_average\",\n",
    "    \"tta16_av\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_continuee/TTAugAdapter_SmolVLM2_2B_16_SimplePara_average\",\n",
    "    \"tta32_av\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_continuee/TTAugAdapter_SmolVLM2_2B_32_SimplePara_average\",\n",
    "    \"tta64_av\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_continuee64/TTAugAdapter_SmolVLM2_2B_64_SimplePara_average\",\n",
    "}, n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>tta16_av_gpt_in_other</th>\n",
       "      <th>tta16_av_self_in_other</th>\n",
       "      <th>tta16_av_classical_wo_consistency</th>\n",
       "      <th>tta16_av_classical_augmix</th>\n",
       "      <th>tta16_av_classical_low</th>\n",
       "      <th>tta16_av_classical_medium</th>\n",
       "      <th>tta16_av_classical_gen</th>\n",
       "      <th>tta16_av_classical_textonly</th>\n",
       "      <th>tta16_av_classical_imageonly</th>\n",
       "      <th>tta16_av_classical_low_imageonly</th>\n",
       "      <th>tta_16_classical_learnedweights_noreg_hypchanged</th>\n",
       "      <th>tta_16_classical_learnedmodel_subset_new_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MME-RealWorld-Lite_rating.json (Accuracy)</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>32.1</td>\n",
       "      <td>32.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>32.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>31.6</td>\n",
       "      <td>26.6</td>\n",
       "      <td>27.7</td>\n",
       "      <td>30.9</td>\n",
       "      <td>31.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCRBench_score.json (Accuracy)</td>\n",
       "      <td>73.5</td>\n",
       "      <td>72.8</td>\n",
       "      <td>70.6</td>\n",
       "      <td>72.4</td>\n",
       "      <td>73.7</td>\n",
       "      <td>73.3</td>\n",
       "      <td>65.3</td>\n",
       "      <td>73.1</td>\n",
       "      <td>73.3</td>\n",
       "      <td>73.8</td>\n",
       "      <td>73.0</td>\n",
       "      <td>70.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChartQA_TEST_acc</td>\n",
       "      <td>76.9</td>\n",
       "      <td>76.6</td>\n",
       "      <td>71.4</td>\n",
       "      <td>74.1</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.4</td>\n",
       "      <td>75.7</td>\n",
       "      <td>75.8</td>\n",
       "      <td>74.7</td>\n",
       "      <td>74.2</td>\n",
       "      <td>76.1</td>\n",
       "      <td>76.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GQA_TestDev_Balanced_acc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OCRVQA_TEST_acc</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.1</td>\n",
       "      <td>10.6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI2D_TEST_acc</td>\n",
       "      <td>69.9</td>\n",
       "      <td>68.4</td>\n",
       "      <td>63.9</td>\n",
       "      <td>68.9</td>\n",
       "      <td>69.1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.1</td>\n",
       "      <td>69.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>69.7</td>\n",
       "      <td>67.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TextVQA_VAL_acc</td>\n",
       "      <td>73.5</td>\n",
       "      <td>74.0</td>\n",
       "      <td>63.9</td>\n",
       "      <td>72.4</td>\n",
       "      <td>72.6</td>\n",
       "      <td>73.3</td>\n",
       "      <td>71.6</td>\n",
       "      <td>73.0</td>\n",
       "      <td>74.2</td>\n",
       "      <td>73.9</td>\n",
       "      <td>74.2</td>\n",
       "      <td>70.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMBER_score</td>\n",
       "      <td>68.8</td>\n",
       "      <td>72.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>77.3</td>\n",
       "      <td>77.0</td>\n",
       "      <td>75.9</td>\n",
       "      <td>76.2</td>\n",
       "      <td>77.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>67.9</td>\n",
       "      <td>76.9</td>\n",
       "      <td>72.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COCO_VAL_score.json (ROUGE_L)</td>\n",
       "      <td>20.6</td>\n",
       "      <td>46.1</td>\n",
       "      <td>13.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>17.8</td>\n",
       "      <td>17.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.8</td>\n",
       "      <td>16.4</td>\n",
       "      <td>35.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mean</td>\n",
       "      <td>46.2</td>\n",
       "      <td>48.5</td>\n",
       "      <td>45.1</td>\n",
       "      <td>47.9</td>\n",
       "      <td>48.4</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>48.2</td>\n",
       "      <td>43.5</td>\n",
       "      <td>43.9</td>\n",
       "      <td>48.3</td>\n",
       "      <td>50.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Metric  tta16_av_gpt_in_other  \\\n",
       "0  MME-RealWorld-Lite_rating.json (Accuracy)                   30.0   \n",
       "1             OCRBench_score.json (Accuracy)                   73.5   \n",
       "2                           ChartQA_TEST_acc                   76.9   \n",
       "3                   GQA_TestDev_Balanced_acc                    0.0   \n",
       "4                            OCRVQA_TEST_acc                    2.6   \n",
       "5                              AI2D_TEST_acc                   69.9   \n",
       "6                            TextVQA_VAL_acc                   73.5   \n",
       "7                                AMBER_score                   68.8   \n",
       "8              COCO_VAL_score.json (ROUGE_L)                   20.6   \n",
       "9                                       Mean                   46.2   \n",
       "\n",
       "   tta16_av_self_in_other  tta16_av_classical_wo_consistency  \\\n",
       "0                    25.9                               32.1   \n",
       "1                    72.8                               70.6   \n",
       "2                    76.6                               71.4   \n",
       "3                     0.0                               31.2   \n",
       "4                     0.0                                0.0   \n",
       "5                    68.4                               63.9   \n",
       "6                    74.0                               63.9   \n",
       "7                    72.9                               60.0   \n",
       "8                    46.1                               13.2   \n",
       "9                    48.5                               45.1   \n",
       "\n",
       "   tta16_av_classical_augmix  tta16_av_classical_low  \\\n",
       "0                       32.1                    31.8   \n",
       "1                       72.4                    73.7   \n",
       "2                       74.1                    77.0   \n",
       "3                        3.1                     4.1   \n",
       "4                       12.9                    12.1   \n",
       "5                       68.9                    69.1   \n",
       "6                       72.4                    72.6   \n",
       "7                       77.3                    77.0   \n",
       "8                       17.8                    17.8   \n",
       "9                       47.9                    48.4   \n",
       "\n",
       "   tta16_av_classical_medium  tta16_av_classical_gen  \\\n",
       "0                       32.5                    31.1   \n",
       "1                       73.3                    65.3   \n",
       "2                       76.4                    75.7   \n",
       "3                        3.7                     2.5   \n",
       "4                       10.6                    12.0   \n",
       "5                       69.0                    67.0   \n",
       "6                       73.3                    71.6   \n",
       "7                       75.9                    76.2   \n",
       "8                       17.1                    18.0   \n",
       "9                       48.0                    46.6   \n",
       "\n",
       "   tta16_av_classical_textonly  tta16_av_classical_imageonly  \\\n",
       "0                         31.6                          26.6   \n",
       "1                         73.1                          73.3   \n",
       "2                         75.8                          74.7   \n",
       "3                          2.0                           0.0   \n",
       "4                         13.5                           0.0   \n",
       "5                         68.1                          69.8   \n",
       "6                         73.0                          74.2   \n",
       "7                         77.3                          64.7   \n",
       "8                         19.0                           8.4   \n",
       "9                         48.2                          43.5   \n",
       "\n",
       "   tta16_av_classical_low_imageonly  \\\n",
       "0                              27.7   \n",
       "1                              73.8   \n",
       "2                              74.2   \n",
       "3                               0.0   \n",
       "4                               0.0   \n",
       "5                              69.2   \n",
       "6                              73.9   \n",
       "7                              67.9   \n",
       "8                               8.8   \n",
       "9                              43.9   \n",
       "\n",
       "   tta_16_classical_learnedweights_noreg_hypchanged  \\\n",
       "0                                              30.9   \n",
       "1                                              73.0   \n",
       "2                                              76.1   \n",
       "3                                               5.2   \n",
       "4                                              11.9   \n",
       "5                                              69.7   \n",
       "6                                              74.2   \n",
       "7                                              76.9   \n",
       "8                                              16.4   \n",
       "9                                              48.3   \n",
       "\n",
       "   tta_16_classical_learnedmodel_subset_new_2  \n",
       "0                                        31.4  \n",
       "1                                        70.5  \n",
       "2                                        76.7  \n",
       "3                                        13.5  \n",
       "4                                        13.8  \n",
       "5                                        67.4  \n",
       "6                                        70.5  \n",
       "7                                        72.8  \n",
       "8                                        35.9  \n",
       "9                                        50.3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_table_from_dict_fillna({\n",
    "    ## before this, text aug was classical\n",
    "    \"tta16_av_gpt_in_other\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_auggpt16/TTAugAdapter_SmolVLM2_2B_16_AugGPTPara_average\",\n",
    "    \"tta16_av_self_in_other\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_selfpara16/TTAugAdapter_SmolVLM2_2B_16_SimplePara_average\",\n",
    "    \"tta16_av_classical_wo_consistency\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_16classicalwoconsist/TTAugAdapter_SmolVLM2_2B_16_SimplePara_average_wo_consistency\",\n",
    "\n",
    "\n",
    "    ## before this, img aug was hard\n",
    "    \"tta16_av_classical_augmix\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_16_simple_mid_low_augmix/TTAugAdapter_SmolVLM2_2B_16_SimplePara_augmix_average\",\n",
    "    \"tta16_av_classical_low\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_16_simple_mid_low_augmix/TTAugAdapter_SmolVLM2_2B_16_SimplePara_low_average\",\n",
    "    \"tta16_av_classical_medium\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_16_simple_mid_low_augmix/TTAugAdapter_SmolVLM2_2B_16_SimplePara_medium_average\",\n",
    "    \"tta16_av_classical_gen\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_classicalgener/TTAugAdapter_SmolVLM2_2B_16_SimplePara_GenImg_average\",\n",
    "\n",
    "\n",
    "    ## decomposition\n",
    "    \"tta16_av_classical_textonly\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_16classical_textonly/TTAugAdapter_SmolVLM2_2B_16_SimplePara_average_textonly\",\n",
    "    \"tta16_av_classical_imageonly\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_16classical_imageonly/TTAugAdapter_SmolVLM2_2B_16_SimplePara_average_imageonly\",\n",
    "    \"tta16_av_classical_low_imageonly\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_16classical_imageonly_low/TTAugAdapter_SmolVLM2_2B_16_SimplePara_average_imageonly\",\n",
    "\n",
    "\n",
    "    ## adaptation objectives\n",
    "    \"tta_16_classical_learnedweights_noreg_hypchanged\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_simpleaugs_learnedweights_noreg_hypchanged/TTAugAdapter_SmolVLM2_2B_16_SimplePara_learnedweights\",\n",
    "    \"tta_16_classical_learnedmodel_subset_new_2\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_simpleaugs_learnedmodel_subset_new_2/TTAugAdapter_SmolVLM2_2B_16_SimplePara_learnedmodel\",\n",
    "}, n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>base</th>\n",
       "      <th>tta_16_classical_earlylayer4</th>\n",
       "      <th>tta_16_classical_earlylayer8</th>\n",
       "      <th>tta_16_classical_earlylayer10</th>\n",
       "      <th>tta_16_classical_earlylayer12</th>\n",
       "      <th>tta_16_classical_earlylayer16</th>\n",
       "      <th>tta_16_classical_earlylayer20</th>\n",
       "      <th>tta_16_classical_earlylayer22</th>\n",
       "      <th>tta_16_classical_earlylayer23</th>\n",
       "      <th>tta_16_av_logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MME-RealWorld-Lite_rating.json (Accuracy)</td>\n",
       "      <td>27.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>24.4</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.9</td>\n",
       "      <td>30.1</td>\n",
       "      <td>30.7</td>\n",
       "      <td>31.7</td>\n",
       "      <td>30.2</td>\n",
       "      <td>31.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCRBench_score.json (Accuracy)</td>\n",
       "      <td>72.9</td>\n",
       "      <td>24.3</td>\n",
       "      <td>43.5</td>\n",
       "      <td>47.4</td>\n",
       "      <td>49.6</td>\n",
       "      <td>51.2</td>\n",
       "      <td>65.0</td>\n",
       "      <td>70.2</td>\n",
       "      <td>72.8</td>\n",
       "      <td>73.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChartQA_TEST_acc</td>\n",
       "      <td>74.2</td>\n",
       "      <td>17.5</td>\n",
       "      <td>41.6</td>\n",
       "      <td>39.1</td>\n",
       "      <td>46.5</td>\n",
       "      <td>49.9</td>\n",
       "      <td>69.8</td>\n",
       "      <td>74.3</td>\n",
       "      <td>75.2</td>\n",
       "      <td>76.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GQA_TestDev_Balanced_acc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OCRVQA_TEST_acc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI2D_TEST_acc</td>\n",
       "      <td>68.5</td>\n",
       "      <td>50.1</td>\n",
       "      <td>61.8</td>\n",
       "      <td>64.4</td>\n",
       "      <td>65.9</td>\n",
       "      <td>68.0</td>\n",
       "      <td>69.6</td>\n",
       "      <td>68.2</td>\n",
       "      <td>69.2</td>\n",
       "      <td>69.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TextVQA_VAL_acc</td>\n",
       "      <td>73.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>44.8</td>\n",
       "      <td>49.4</td>\n",
       "      <td>47.0</td>\n",
       "      <td>61.4</td>\n",
       "      <td>69.2</td>\n",
       "      <td>71.8</td>\n",
       "      <td>72.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMBER_score</td>\n",
       "      <td>68.7</td>\n",
       "      <td>41.3</td>\n",
       "      <td>70.4</td>\n",
       "      <td>68.6</td>\n",
       "      <td>74.4</td>\n",
       "      <td>74.6</td>\n",
       "      <td>73.6</td>\n",
       "      <td>79.7</td>\n",
       "      <td>74.7</td>\n",
       "      <td>75.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COCO_VAL_score.json (ROUGE_L)</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>25.1</td>\n",
       "      <td>19.7</td>\n",
       "      <td>18.7</td>\n",
       "      <td>16.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>16.4</td>\n",
       "      <td>16.5</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mean</td>\n",
       "      <td>43.8</td>\n",
       "      <td>18.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>43.4</td>\n",
       "      <td>47.3</td>\n",
       "      <td>47.8</td>\n",
       "      <td>48.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Metric  base  \\\n",
       "0  MME-RealWorld-Lite_rating.json (Accuracy)  27.8   \n",
       "1             OCRBench_score.json (Accuracy)  72.9   \n",
       "2                           ChartQA_TEST_acc  74.2   \n",
       "3                   GQA_TestDev_Balanced_acc   0.0   \n",
       "4                            OCRVQA_TEST_acc   0.0   \n",
       "5                              AI2D_TEST_acc  68.5   \n",
       "6                            TextVQA_VAL_acc  73.2   \n",
       "7                                AMBER_score  68.7   \n",
       "8              COCO_VAL_score.json (ROUGE_L)   9.1   \n",
       "9                                       Mean  43.8   \n",
       "\n",
       "   tta_16_classical_earlylayer4  tta_16_classical_earlylayer8  \\\n",
       "0                           5.6                          24.4   \n",
       "1                          24.3                          43.5   \n",
       "2                          17.5                          41.6   \n",
       "3                           2.5                           0.7   \n",
       "4                           3.2                           0.9   \n",
       "5                          50.1                          61.8   \n",
       "6                          15.0                          43.0   \n",
       "7                          41.3                          70.4   \n",
       "8                           8.2                          25.1   \n",
       "9                          18.6                          34.6   \n",
       "\n",
       "   tta_16_classical_earlylayer10  tta_16_classical_earlylayer12  \\\n",
       "0                           25.4                           30.9   \n",
       "1                           47.4                           49.6   \n",
       "2                           39.1                           46.5   \n",
       "3                            0.3                            0.2   \n",
       "4                            2.7                            5.9   \n",
       "5                           64.4                           65.9   \n",
       "6                           44.8                           49.4   \n",
       "7                           68.6                           74.4   \n",
       "8                           19.7                           18.7   \n",
       "9                           34.7                           38.0   \n",
       "\n",
       "   tta_16_classical_earlylayer16  tta_16_classical_earlylayer20  \\\n",
       "0                           30.1                           30.7   \n",
       "1                           51.2                           65.0   \n",
       "2                           49.9                           69.8   \n",
       "3                            0.1                            0.5   \n",
       "4                            4.0                            4.0   \n",
       "5                           68.0                           69.6   \n",
       "6                           47.0                           61.4   \n",
       "7                           74.6                           73.6   \n",
       "8                           16.8                           15.7   \n",
       "9                           38.0                           43.4   \n",
       "\n",
       "   tta_16_classical_earlylayer22  tta_16_classical_earlylayer23  \\\n",
       "0                           31.7                           30.2   \n",
       "1                           70.2                           72.8   \n",
       "2                           74.3                           75.2   \n",
       "3                            5.1                            6.8   \n",
       "4                           11.1                           12.9   \n",
       "5                           68.2                           69.2   \n",
       "6                           69.2                           71.8   \n",
       "7                           79.7                           74.7   \n",
       "8                           16.4                           16.5   \n",
       "9                           47.3                           47.8   \n",
       "\n",
       "   tta_16_av_logits  \n",
       "0              31.9  \n",
       "1              73.7  \n",
       "2              76.1  \n",
       "3               5.5  \n",
       "4              12.6  \n",
       "5              69.6  \n",
       "6              72.4  \n",
       "7              75.9  \n",
       "8              16.9  \n",
       "9              48.3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appendix: Aggregation at Earlier Layers \n",
    "create_table_from_dict_fillna({\n",
    "    \"base\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized/Base_SmolVLM2_2B\",\n",
    "    \"tta_16_classical_earlylayer4\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_16_earlierlayers/TTAugAdapter_SmolVLM2_2B_16_SimplePara_AverageEarlyLayer4\",\n",
    "    \"tta_16_classical_earlylayer8\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_16_earlierlayers/TTAugAdapter_SmolVLM2_2B_16_SimplePara_AverageEarlyLayer8\",\n",
    "    \"tta_16_classical_earlylayer10\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_16_earlierlayers/TTAugAdapter_SmolVLM2_2B_16_SimplePara_AverageEarlyLayer10\",\n",
    "    \"tta_16_classical_earlylayer12\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_16_earlierlayers/TTAugAdapter_SmolVLM2_2B_16_SimplePara_AverageEarlyLayer12\",\n",
    "    \"tta_16_classical_earlylayer16\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_16_earlierlayers/TTAugAdapter_SmolVLM2_2B_16_SimplePara_AverageEarlyLayer16\",\n",
    "    \"tta_16_classical_earlylayer20\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_16_earlierlayers/TTAugAdapter_SmolVLM2_2B_16_SimplePara_AverageEarlyLayer20\",\n",
    "    \"tta_16_classical_earlylayer22\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_16_earlierlayers/TTAugAdapter_SmolVLM2_2B_16_SimplePara_AverageEarlyLayer22\",\n",
    "    \"tta_16_classical_earlylayer23\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_16_earlierlayers/TTAugAdapter_SmolVLM2_2B_16_SimplePara_AverageEarlyLayer23\",\n",
    "    \"tta_16_av_logits\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_continuee/TTAugAdapter_SmolVLM2_2B_16_SimplePara_average\",\n",
    "}, n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>base256m</th>\n",
       "      <th>tta_16_classical_average_256m_repeat</th>\n",
       "      <th>tta_16_classical_learnedmodel_256m</th>\n",
       "      <th>base500m</th>\n",
       "      <th>tta_16_classical_average_500m</th>\n",
       "      <th>tta_16_classical_learnedmodel_500m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MME-RealWorld-Lite_rating.json (Accuracy)</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.4</td>\n",
       "      <td>20.7</td>\n",
       "      <td>27.6</td>\n",
       "      <td>27.6</td>\n",
       "      <td>27.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCRBench_score.json (Accuracy)</td>\n",
       "      <td>56.7</td>\n",
       "      <td>53.3</td>\n",
       "      <td>50.3</td>\n",
       "      <td>61.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>57.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChartQA_TEST_acc</td>\n",
       "      <td>65.1</td>\n",
       "      <td>59.4</td>\n",
       "      <td>55.1</td>\n",
       "      <td>64.1</td>\n",
       "      <td>64.8</td>\n",
       "      <td>65.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GQA_TestDev_Balanced_acc</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OCRVQA_TEST_acc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI2D_TEST_acc</td>\n",
       "      <td>37.0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>56.6</td>\n",
       "      <td>55.3</td>\n",
       "      <td>52.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TextVQA_VAL_acc</td>\n",
       "      <td>47.8</td>\n",
       "      <td>45.1</td>\n",
       "      <td>40.1</td>\n",
       "      <td>59.9</td>\n",
       "      <td>58.0</td>\n",
       "      <td>57.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMBER_score</td>\n",
       "      <td>29.5</td>\n",
       "      <td>53.3</td>\n",
       "      <td>43.0</td>\n",
       "      <td>55.3</td>\n",
       "      <td>56.1</td>\n",
       "      <td>52.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COCO_VAL_score.json (ROUGE_L)</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>38.5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>31.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mean</td>\n",
       "      <td>31.8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.4</td>\n",
       "      <td>36.7</td>\n",
       "      <td>37.3</td>\n",
       "      <td>38.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Metric  base256m  \\\n",
       "0  MME-RealWorld-Lite_rating.json (Accuracy)      21.0   \n",
       "1             OCRBench_score.json (Accuracy)      56.7   \n",
       "2                           ChartQA_TEST_acc      65.1   \n",
       "3                   GQA_TestDev_Balanced_acc       0.1   \n",
       "4                            OCRVQA_TEST_acc       0.2   \n",
       "5                              AI2D_TEST_acc      37.0   \n",
       "6                            TextVQA_VAL_acc      47.8   \n",
       "7                                AMBER_score      29.5   \n",
       "8              COCO_VAL_score.json (ROUGE_L)      29.0   \n",
       "9                                       Mean      31.8   \n",
       "\n",
       "   tta_16_classical_average_256m_repeat  tta_16_classical_learnedmodel_256m  \\\n",
       "0                                  21.4                                20.7   \n",
       "1                                  53.3                                50.3   \n",
       "2                                  59.4                                55.1   \n",
       "3                                   5.8                                18.4   \n",
       "4                                   0.4                                 0.3   \n",
       "5                                  35.4                                34.0   \n",
       "6                                  45.1                                40.1   \n",
       "7                                  53.3                                43.0   \n",
       "8                                  40.6                                38.5   \n",
       "9                                  35.0                                33.4   \n",
       "\n",
       "   base500m  tta_16_classical_average_500m  tta_16_classical_learnedmodel_500m  \n",
       "0      27.6                           27.6                                27.2  \n",
       "1      61.0                           60.0                                57.6  \n",
       "2      64.1                           64.8                                65.5  \n",
       "3       0.0                            0.0                                 0.9  \n",
       "4       0.0                            4.6                                 5.2  \n",
       "5      56.6                           55.3                                52.1  \n",
       "6      59.9                           58.0                                57.7  \n",
       "7      55.3                           56.1                                52.8  \n",
       "8       6.2                            9.2                                31.6  \n",
       "9      36.7                           37.3                                38.9  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-Model Generalization: Different Parameter Sizes\n",
    "create_table_from_dict_fillna({\n",
    "    \"base256m\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_continueeeee/Base_SmolVLM2_256M\",\n",
    "    \"tta_16_classical_average_256m_repeat\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_simpleaugs_tta_av_othermodels/TTAugAdapter_SmolVLM2_256M_16_SimplePara_average\",\n",
    "    \"tta_16_classical_learnedmodel_256m\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_simpleaugs_learnedmodel_subset_new_2_othermodels/TTAugAdapter_SmolVLM2_256M_16_SimplePara_learnedmodel\",\n",
    "\n",
    "    \"base500m\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_continueeeee/Base_SmolVLM2_500M\",\n",
    "    \"tta_16_classical_average_500m\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_simpleaugs_tta_av_othermodels/TTAugAdapter_SmolVLM2_500M_16_SimplePara_average\",\n",
    "    \"tta_16_classical_learnedmodel_500m\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_simpleaugs_learnedmodel_subset_new_2_othermodels/TTAugAdapter_SmolVLM2_500M_16_SimplePara_learnedmodel\",\n",
    "}, n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>InternVL2_1B</th>\n",
       "      <th>TTAugAdapter_InternVLChat2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MME-RealWorld-Lite_rating.json (Accuracy)</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCRBench_score.json (Accuracy)</td>\n",
       "      <td>75.7</td>\n",
       "      <td>75.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChartQA_TEST_acc</td>\n",
       "      <td>72.1</td>\n",
       "      <td>72.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GQA_TestDev_Balanced_acc</td>\n",
       "      <td>52.0</td>\n",
       "      <td>51.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OCRVQA_TEST_acc</td>\n",
       "      <td>43.3</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI2D_TEST_acc</td>\n",
       "      <td>52.8</td>\n",
       "      <td>52.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TextVQA_VAL_acc</td>\n",
       "      <td>69.6</td>\n",
       "      <td>67.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMBER_score</td>\n",
       "      <td>72.6</td>\n",
       "      <td>75.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COCO_VAL_score.json (ROUGE_L)</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mean</td>\n",
       "      <td>52.1</td>\n",
       "      <td>52.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Metric  InternVL2_1B  \\\n",
       "0  MME-RealWorld-Lite_rating.json (Accuracy)          13.5   \n",
       "1             OCRBench_score.json (Accuracy)          75.7   \n",
       "2                           ChartQA_TEST_acc          72.1   \n",
       "3                   GQA_TestDev_Balanced_acc          52.0   \n",
       "4                            OCRVQA_TEST_acc          43.3   \n",
       "5                              AI2D_TEST_acc          52.8   \n",
       "6                            TextVQA_VAL_acc          69.6   \n",
       "7                                AMBER_score          72.6   \n",
       "8              COCO_VAL_score.json (ROUGE_L)          17.2   \n",
       "9                                       Mean          52.1   \n",
       "\n",
       "   TTAugAdapter_InternVLChat2  \n",
       "0                        13.3  \n",
       "1                        75.1  \n",
       "2                        72.1  \n",
       "3                        51.3  \n",
       "4                        42.0  \n",
       "5                        52.6  \n",
       "6                        67.6  \n",
       "7                        75.7  \n",
       "8                        24.6  \n",
       "9                        52.7  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-Model Generalization: InternVL2\n",
    "create_table_from_dict_fillna({\n",
    "    \"InternVL2_1B\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_differentarchitecture1000/InternVL2_1B\",\n",
    "    \"TTAugAdapter_InternVLChat2\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_8augcount_newdatasets_finalized_differentarchitecture1000/TTAugAdapter_InternVLChat2_10_av_noimgaug\",\n",
    "}, n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Ovis2_1B</th>\n",
       "      <th>TTAug_Ovis2_1B_16_average</th>\n",
       "      <th>Ovis2</th>\n",
       "      <th>TTAug_Ovis2_2B_16_average</th>\n",
       "      <th>Ovis2_4B</th>\n",
       "      <th>TTAug_Ovis2_4B_16_average</th>\n",
       "      <th>Ovis2_8B</th>\n",
       "      <th>TTAug_Ovis2_8B_16_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MME-RealWorld-Lite_rating.json (Accuracy)</td>\n",
       "      <td>35.5</td>\n",
       "      <td>35.6</td>\n",
       "      <td>38.6</td>\n",
       "      <td>40.5</td>\n",
       "      <td>45.7</td>\n",
       "      <td>44.1</td>\n",
       "      <td>45.7</td>\n",
       "      <td>46.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCRBench_score.json (Accuracy)</td>\n",
       "      <td>88.8</td>\n",
       "      <td>84.9</td>\n",
       "      <td>87.3</td>\n",
       "      <td>86.0</td>\n",
       "      <td>91.2</td>\n",
       "      <td>89.2</td>\n",
       "      <td>89.2</td>\n",
       "      <td>87.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChartQA_TEST_acc</td>\n",
       "      <td>80.4</td>\n",
       "      <td>81.6</td>\n",
       "      <td>86.6</td>\n",
       "      <td>85.9</td>\n",
       "      <td>87.6</td>\n",
       "      <td>87.8</td>\n",
       "      <td>87.4</td>\n",
       "      <td>87.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GQA_TestDev_Balanced_acc</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54.3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>58.7</td>\n",
       "      <td>40.5</td>\n",
       "      <td>55.7</td>\n",
       "      <td>59.4</td>\n",
       "      <td>64.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OCRVQA_TEST_acc</td>\n",
       "      <td>74.3</td>\n",
       "      <td>70.5</td>\n",
       "      <td>76.7</td>\n",
       "      <td>73.1</td>\n",
       "      <td>80.2</td>\n",
       "      <td>76.9</td>\n",
       "      <td>79.3</td>\n",
       "      <td>78.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI2D_TEST_acc</td>\n",
       "      <td>76.5</td>\n",
       "      <td>73.3</td>\n",
       "      <td>81.9</td>\n",
       "      <td>82.2</td>\n",
       "      <td>84.9</td>\n",
       "      <td>84.5</td>\n",
       "      <td>87.1</td>\n",
       "      <td>87.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TextVQA_VAL_acc</td>\n",
       "      <td>79.2</td>\n",
       "      <td>77.2</td>\n",
       "      <td>78.8</td>\n",
       "      <td>79.5</td>\n",
       "      <td>83.5</td>\n",
       "      <td>83.9</td>\n",
       "      <td>83.1</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMBER_score</td>\n",
       "      <td>76.1</td>\n",
       "      <td>73.8</td>\n",
       "      <td>84.9</td>\n",
       "      <td>85.9</td>\n",
       "      <td>87.4</td>\n",
       "      <td>87.4</td>\n",
       "      <td>87.3</td>\n",
       "      <td>89.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COCO_VAL_score.json (ROUGE_L)</td>\n",
       "      <td>22.7</td>\n",
       "      <td>13.7</td>\n",
       "      <td>17.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>13.8</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mean</td>\n",
       "      <td>62.6</td>\n",
       "      <td>62.8</td>\n",
       "      <td>65.2</td>\n",
       "      <td>67.2</td>\n",
       "      <td>68.3</td>\n",
       "      <td>69.1</td>\n",
       "      <td>70.3</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Metric  Ovis2_1B  \\\n",
       "0  MME-RealWorld-Lite_rating.json (Accuracy)      35.5   \n",
       "1             OCRBench_score.json (Accuracy)      88.8   \n",
       "2                           ChartQA_TEST_acc      80.4   \n",
       "3                   GQA_TestDev_Balanced_acc      30.0   \n",
       "4                            OCRVQA_TEST_acc      74.3   \n",
       "5                              AI2D_TEST_acc      76.5   \n",
       "6                            TextVQA_VAL_acc      79.2   \n",
       "7                                AMBER_score      76.1   \n",
       "8              COCO_VAL_score.json (ROUGE_L)      22.7   \n",
       "9                                       Mean      62.6   \n",
       "\n",
       "   TTAug_Ovis2_1B_16_average  Ovis2  TTAug_Ovis2_2B_16_average  Ovis2_4B  \\\n",
       "0                       35.6   38.6                       40.5      45.7   \n",
       "1                       84.9   87.3                       86.0      91.2   \n",
       "2                       81.6   86.6                       85.9      87.6   \n",
       "3                       54.3   34.5                       58.7      40.5   \n",
       "4                       70.5   76.7                       73.1      80.2   \n",
       "5                       73.3   81.9                       82.2      84.9   \n",
       "6                       77.2   78.8                       79.5      83.5   \n",
       "7                       73.8   84.9                       85.9      87.4   \n",
       "8                       13.7   17.3                       13.1      14.0   \n",
       "9                       62.8   65.2                       67.2      68.3   \n",
       "\n",
       "   TTAug_Ovis2_4B_16_average  Ovis2_8B  TTAug_Ovis2_8B_16_average  \n",
       "0                       44.1      45.7                       46.5  \n",
       "1                       89.2      89.2                       87.2  \n",
       "2                       87.8      87.4                       87.9  \n",
       "3                       55.7      59.4                       64.2  \n",
       "4                       76.9      79.3                       78.7  \n",
       "5                       84.5      87.1                       87.2  \n",
       "6                       83.9      83.1                       84.0  \n",
       "7                       87.4      87.3                       89.8  \n",
       "8                       12.5      13.8                       13.3  \n",
       "9                       69.1      70.3                       71.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-Model Generalization: Ovis2\n",
    "create_table_from_dict_fillna({\n",
    "    \"Ovis2_1B\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_ovis1000/Ovis2_1B\",\n",
    "    \"TTAug_Ovis2_1B_16_average\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_ovis1000_img/TTAugAdapter_Ovis2_1B_16_SimplePara_average_high\",\n",
    "    \n",
    "    \"Ovis2\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_ovis1000/Ovis2\",\n",
    "    \"TTAug_Ovis2_2B_16_average\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_ovis1000_img/TTAugAdapter_Ovis2_2B_16_SimplePara_average_high\",\n",
    "\n",
    "    \"Ovis2_4B\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_ovis1000/Ovis2_4B\",\n",
    "    \"TTAug_Ovis2_4B_16_average\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_ovis1000_img/TTAugAdapter_Ovis2_4B_16_SimplePara_average_high\",\n",
    "\n",
    "    \"Ovis2_8B\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_ovis1000/Ovis2_8B\",\n",
    "    \"TTAug_Ovis2_8B_16_average\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_ovis1000_img/TTAugAdapter_Ovis2_8B_16_SimplePara_average_low\",\n",
    "}, n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Janus</th>\n",
       "      <th>IDEFICS2</th>\n",
       "      <th>Molmo</th>\n",
       "      <th>XGenMM</th>\n",
       "      <th>LLaVa-onevision-7b</th>\n",
       "      <th>PaliGemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MME-RealWorld-Lite_rating.json (Accuracy)</td>\n",
       "      <td>23.4</td>\n",
       "      <td>34.3</td>\n",
       "      <td>36.8</td>\n",
       "      <td>35.1</td>\n",
       "      <td>31.1</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCRBench_score.json (Accuracy)</td>\n",
       "      <td>58.9</td>\n",
       "      <td>63.4</td>\n",
       "      <td>66.3</td>\n",
       "      <td>55.5</td>\n",
       "      <td>61.2</td>\n",
       "      <td>61.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChartQA_TEST_acc</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>85.8</td>\n",
       "      <td>65.0</td>\n",
       "      <td>72.3</td>\n",
       "      <td>40.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GQA_TestDev_Balanced_acc</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.1</td>\n",
       "      <td>60.2</td>\n",
       "      <td>62.5</td>\n",
       "      <td>61.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OCRVQA_TEST_acc</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.9</td>\n",
       "      <td>70.7</td>\n",
       "      <td>69.5</td>\n",
       "      <td>61.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI2D_TEST_acc</td>\n",
       "      <td>67.5</td>\n",
       "      <td>72.2</td>\n",
       "      <td>80.7</td>\n",
       "      <td>73.5</td>\n",
       "      <td>78.2</td>\n",
       "      <td>67.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TextVQA_VAL_acc</td>\n",
       "      <td>55.0</td>\n",
       "      <td>72.6</td>\n",
       "      <td>81.5</td>\n",
       "      <td>72.8</td>\n",
       "      <td>60.8</td>\n",
       "      <td>70.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMBER_score</td>\n",
       "      <td>74.8</td>\n",
       "      <td>85.4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>82.1</td>\n",
       "      <td>84.4</td>\n",
       "      <td>84.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COCO_VAL_score.json (ROUGE_L)</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>15.7</td>\n",
       "      <td>13.9</td>\n",
       "      <td>45.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mean</td>\n",
       "      <td>38.3</td>\n",
       "      <td>42.7</td>\n",
       "      <td>60.9</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.3</td>\n",
       "      <td>57.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Metric  Janus  IDEFICS2  Molmo  XGenMM  \\\n",
       "0  MME-RealWorld-Lite_rating.json (Accuracy)   23.4      34.3   36.8    35.1   \n",
       "1             OCRBench_score.json (Accuracy)   58.9      63.4   66.3    55.5   \n",
       "2                           ChartQA_TEST_acc   31.0      31.6   85.8    65.0   \n",
       "3                   GQA_TestDev_Balanced_acc   13.7       0.0   55.1    60.2   \n",
       "4                            OCRVQA_TEST_acc    2.5       0.0   44.9    70.7   \n",
       "5                              AI2D_TEST_acc   67.5      72.2   80.7    73.5   \n",
       "6                            TextVQA_VAL_acc   55.0      72.6   81.5    72.8   \n",
       "7                                AMBER_score   74.8      85.4   85.0    82.1   \n",
       "8              COCO_VAL_score.json (ROUGE_L)   18.0      24.4   12.1    15.7   \n",
       "9                                       Mean   38.3      42.7   60.9    59.0   \n",
       "\n",
       "   LLaVa-onevision-7b  PaliGemma  \n",
       "0                31.1       25.4  \n",
       "1                61.2       61.4  \n",
       "2                72.3       40.7  \n",
       "3                62.5       61.5  \n",
       "4                69.5       61.2  \n",
       "5                78.2       67.9  \n",
       "6                60.8       70.7  \n",
       "7                84.4       84.9  \n",
       "8                13.9       45.9  \n",
       "9                59.3       57.7  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appendix: Reference Baseline Models\n",
    "create_table_from_dict_fillna({\n",
    "    \"Janus\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_differentbaselines/Janus\",\n",
    "    \"IDEFICS2\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_differentbaselines/IDEFICS2\",\n",
    "    \"Molmo\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_differentbaselines/molmo\",\n",
    "    \"XGenMM\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_differentbaselines/XGenMM\",\n",
    "    \"LLaVa-onevision-7b\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_differentbaselines/llava-onevision-qwen2-7b-si-hf\",\n",
    "    \"PaliGemma\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_differentbaselines/PaliGemma\",\n",
    "    ## \"LLaVA_Next-8B\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_differentbaselines/LLaVA_Next\",\n",
    "    ## \"Pixtral-12B\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_differentbaselines_pixtral/Pixtral\", # Very slow\n",
    "    ## \"Idefics3-8B\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_differentbaselines/Idefics3-8B-Llama3\",\n",
    "}, n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix: Qualitative Examples\n",
    "# create_table_from_dict_fillna({\n",
    "#     \"Base_SmolVLM2_2B\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_VISUALSAMPLES/Base_SmolVLM2_2B\",\n",
    "#     \"TTAugAdapter_SmolVLM2_2B_16_SimplePara_average\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_VISUALSAMPLES/TTAugAdapter_SmolVLM2_2B_16_SimplePara_average\",\n",
    "#     \"TTAugAdapter_SmolVLM2_2B_16_SimplePara_learnedmodel\": \"/work3/monka/efficient_test_time_scaling_for_small_vlms/benchmark_results/n_samples_1000/exp_83_newdatasets_finalized_VISUALSAMPLES/TTAugAdapter_SmolVLM2_2B_16_SimplePara_learnedmodel\",\n",
    "# }, n_samples=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
